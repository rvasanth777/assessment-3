Overview
This assessment demonstrates the setup of a real-time event-driven architecture using Kafka as the message broker, FastAPI for producing events, Python for consuming and persisting data into PostgreSQL, and Docker Compose for orchestration. It integrates a full monitoring and observability stack using Prometheus, Grafana, Loki, Promtail, Node Exporter, cAdvisor, and Kafka Exporter.

ğŸ§± Project Structure
less
Copy
Edit
assessment-3/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ promtail-config.yml
â”‚
â””â”€â”€ grafana/
    â””â”€â”€ (Optional: dashboards, provisioning, etc.)
âš™ï¸ Technologies Used
Kafka + Zookeeper: Message streaming platform

FastAPI (Producer): Publishes events to Kafka

Python (Consumer): Reads Kafka events and writes to PostgreSQL

PostgreSQL: Database for storing transaction data

Prometheus: Metrics collection and monitoring

Grafana: Visualization dashboard

Loki + Promtail: Log aggregation

Kafka Exporter: Kafka metrics for Prometheus

Node Exporter: System metrics

cAdvisor: Container metrics

ğŸ§ª Setup Instructions
1. âœ… Clone the Repo
bash
Copy
Edit
git clone https://github.com/your-username/assessment-3.git
cd assessment-3
2. âœ… Verify Monitoring Configuration
Make sure the following files exist:

monitoring/prometheus.yml

monitoring/promtail-config.yml

And your docker-compose.yml volume mounts point correctly to them:

yaml
Copy
Edit
prometheus:
  volumes:
    - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

promtail:
  volumes:
    - ./monitoring/promtail-config.yml:/etc/promtail/config.yml
3. âœ… Start the Stack
bash
Copy
Edit
docker-compose down -v  # Stop and remove volumes
docker-compose up -d --build
This will:

Build and start all services

Automatically run producer and consumer

Connect Prometheus to exporters and services

ğŸ” Verifying Components
Kafka UI: http://localhost:8080

Grafana: http://localhost:3000 (Default: admin/admin)

Prometheus: http://localhost:9090

Loki: http://localhost:3100

ğŸ“¤ Produce Transactions
Use Postman or curl to test the API:

bash
Copy
Edit
curl -X POST http://localhost:8000/produce \
     -H "Content-Type: application/json" \
     -d '{"transaction_id": 101, "amount": 5000, "type": "credit"}'
ğŸ“¥ Consume & Store in PostgreSQL
Consumer service will automatically read messages from Kafka and insert them into PostgreSQL.

ğŸ“Š Monitoring Dashboards (Grafana)
You can create panels for:

Kafka metrics via Kafka Exporter

System metrics via Node Exporter

Container stats via cAdvisor

Consumer & Producer log monitoring via Loki

Prometheus uptime and custom metrics

ğŸ› Troubleshooting Tips
Mount error: Make sure all host paths in volumes: exist and are valid files or directories.

Duplicate mount points: Clean up old entries or conflicting volumes: in docker-compose.yml.

Prometheus.yml error: Ensure correct YAML formatting and that the file is not a directory.

âœ… Status
âœ… Kafka, Producer, Consumer, PostgreSQL
âœ… Prometheus + Exporters
âœ… Grafana Dashboards
âœ… Loki + Promtail for logs
âœ… Containerized with Docker Compose
